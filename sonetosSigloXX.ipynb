{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "%load_ext autoreload\n",
    "%autoreload 2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "sonetos = np.load('sonetosSigloXIX.npy')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(2695,)"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "sonetos.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 70,
   "metadata": {},
   "outputs": [],
   "source": [
    "from models import replace_chars\n",
    "input_text = []\n",
    "target_text = []\n",
    "for soneto in sonetos:\n",
    "    soneto = replace_chars(soneto.lower())\n",
    "    input_text.append('<sos> ' + soneto)\n",
    "    target_text.append(soneto + ' <eos>')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 71,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'<sos> y miras a jesús char_comma  virgen maría char_exclamation_close  char_new_line y latiendo tu pecho de quebranto char_new_line a mares viertes congojoso llanto char_new_line y aun brama de furor la turna impía char_exclamation_close  char_new_line  char_new_line  char_exclamation_open y goza contemplando su agonía char_comma  char_new_line y no se abate de mortal espanto char_exclamation_close  char_dot  char_dot  char_dot  char_new_line  char_exclamation_open y al ver la pena en tu semblante santo char_new_line su alma a la piedad se ostenta fría char_exclamation_close  char_new_line  char_new_line  char_question_open mas char_comma  quién char_comma   char_exclamation_open maría char_exclamation_close  brindará consuelo char_new_line a la honda angustia que en tu ser impera char_comma  char_new_line si ella cubre a la vez de luto el cielo char_question_close  char_new_line  char_new_line  char_exclamation_open y es tan ardiente y tan profunda y fiera char_comma  char_new_line que si al mundo asaltase tanto duelo char_comma  char_new_line roto en pedazos con fragor muriera char_exclamation_close  char_new_line  char_new_line '"
      ]
     },
     "execution_count": 71,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "input_text[2]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 93,
   "metadata": {},
   "outputs": [],
   "source": [
    "from keras.preprocessing.text import Tokenizer\n",
    "from keras.preprocessing.sequence import pad_sequences"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 73,
   "metadata": {},
   "outputs": [],
   "source": [
    "tokenizer = Tokenizer(filters='')\n",
    "tokenizer.fit_on_texts(input_text + target_text)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 74,
   "metadata": {},
   "outputs": [],
   "source": [
    "input_sonetos = tokenizer.texts_to_sequences(input_text)\n",
    "target_sonetos = tokenizer.texts_to_sequences(target_text)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 85,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "24679"
      ]
     },
     "execution_count": 85,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(tokenizer.word_index)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 103,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "28"
      ]
     },
     "execution_count": 103,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "tokenizer.word_index['<eos>']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 76,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[27, 12122, 9, 51, 386, 277, 12123, 2, 1, 69]\n",
      "[12122, 9, 51, 386, 277, 12123, 2, 1, 69, 38]\n"
     ]
    }
   ],
   "source": [
    "print(input_sonetos[0][:10])\n",
    "print(target_sonetos[0][:10])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 77,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[25, 3827, 8, 22, 3374, 4, 2283, 3, 1, 1]\n",
      "[3827, 8, 22, 3374, 4, 2283, 3, 1, 1, 28]\n"
     ]
    }
   ],
   "source": [
    "print(input_sonetos[0][-10:])\n",
    "print(target_sonetos[0][-10:])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 84,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(138, 138)"
      ]
     },
     "execution_count": 84,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(input_sonetos[0]), len(target_sonetos[0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 106,
   "metadata": {},
   "outputs": [],
   "source": [
    "MAX_LEN = max([len(soneto) for soneto in input_sonetos])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 107,
   "metadata": {},
   "outputs": [],
   "source": [
    "VOCAB_SIZE = len(tokenizer.word_index)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 94,
   "metadata": {},
   "outputs": [],
   "source": [
    "input_sonetos_padded = pad_sequences(input_sonetos, maxlen=MAX_LEN, padding='post')\n",
    "target_sonetos_padded = pad_sequences(target_sonetos, maxlen=MAX_LEN, padding='post')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 104,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[   27 12122     9    51   386   277 12123     2     1    69    38  1009\n",
      "    48  1196     2     5 12124     3     1   629    26  2280     2   585\n",
      "     2     8   102    63  1814     2     1     9    23   175     9   686\n",
      "     4   122  8226     3     1     1    35  4396     9     4    51   305\n",
      "  8227     2     1     9     7   205  2719     5  2461    69  8228     1\n",
      "    44     2   606 12125     2 12126    36     1    19    94  2281     9\n",
      "    41  2282     2    25  8229    18     1     1   540    10   460     3\n",
      " 12127     2   585   109     3     1    80  2280    23    26     2 12128\n",
      "     2    32   607     3     1   276   111     2    94  8230   386    47\n",
      "   282  5236     3     1     1   777     2  5237     2   257   156  5238\n",
      "     2     1    44 12129 12130     2 12131     1    25  3827     8    22\n",
      "  3374     4  2283     3     1     1     0     0     0     0     0     0\n",
      "     0     0     0     0     0     0]\n",
      "[12122     9    51   386   277 12123     2     1    69    38  1009    48\n",
      "  1196     2     5 12124     3     1   629    26  2280     2   585     2\n",
      "     8   102    63  1814     2     1     9    23   175     9   686     4\n",
      "   122  8226     3     1     1    35  4396     9     4    51   305  8227\n",
      "     2     1     9     7   205  2719     5  2461    69  8228     1    44\n",
      "     2   606 12125     2 12126    36     1    19    94  2281     9    41\n",
      "  2282     2    25  8229    18     1     1   540    10   460     3 12127\n",
      "     2   585   109     3     1    80  2280    23    26     2 12128     2\n",
      "    32   607     3     1   276   111     2    94  8230   386    47   282\n",
      "  5236     3     1     1   777     2  5237     2   257   156  5238     2\n",
      "     1    44 12129 12130     2 12131     1    25  3827     8    22  3374\n",
      "     4  2283     3     1     1    28     0     0     0     0     0     0\n",
      "     0     0     0     0     0     0]\n"
     ]
    }
   ],
   "source": [
    "print(input_sonetos_padded[0][:150])\n",
    "print(target_sonetos_padded[0][:150])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 117,
   "metadata": {},
   "outputs": [],
   "source": [
    "from keras.utils import to_categorical"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 122,
   "metadata": {},
   "outputs": [],
   "source": [
    "target_sonetos_padded_cat = to_categorical(target_sonetos_padded-1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 124,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(2695, 187, 24679)"
      ]
     },
     "execution_count": 124,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "target_sonetos_padded_cat.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 125,
   "metadata": {},
   "outputs": [],
   "source": [
    "from keras.models import Sequential\n",
    "from keras.layers import Embedding, LSTM, Dense"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 126,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "embedding_5 (Embedding)      (None, None, 64)          1579520   \n",
      "_________________________________________________________________\n",
      "lstm_5 (LSTM)                (None, None, 128)         98816     \n",
      "_________________________________________________________________\n",
      "dense_4 (Dense)              (None, None, 24679)       3183591   \n",
      "=================================================================\n",
      "Total params: 4,861,927\n",
      "Trainable params: 4,861,927\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "word_dim = 64\n",
    "lstm_units = 128\n",
    "model = Sequential()\n",
    "model.add(Embedding(VOCAB_SIZE+1, word_dim, mask_zero = True))\n",
    "model.add(LSTM(lstm_units, return_sequences=True))\n",
    "model.add(Dense(VOCAB_SIZE, activation=\"softmax\"))\n",
    "model.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Begin training\n",
      "Epoch 1/2\n",
      "   4/2695 [..............................] - ETA: 1:45:26 - loss: 10.1116 - acc: 0.0931"
     ]
    }
   ],
   "source": [
    "from fnn_helper import PlotLosses\n",
    "plot_losses = PlotLosses(plot_interval=1, evaluate_interval=None)\n",
    "model.compile(loss='categorical_crossentropy', optimizer='adam', metrics=['accuracy'])\n",
    "model.fit(input_sonetos_padded, \n",
    "          target_sonetos_padded_cat, \n",
    "          batch_size=1, epochs=2, verbose = 1, callbacks=[plot_losses])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
